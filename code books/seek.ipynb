{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = \"http://192.198.126.179:7222\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = []\n",
    "Category = []\n",
    "def seek_extractor():#this functions extracts the job links from the particular websie\n",
    "    try:\n",
    "        for i in range(0,10): # iterates upto 10 pages\n",
    "            url_next='https://www.seek.co.nz/data-science-jobs?page='+str(i)\n",
    "            w1=requests.get(url_next,proxy) # to access the url\n",
    "            soups=BeautifulSoup(w1.content,'html.parser') \n",
    "            soup = soups.findAll(class_=\"_1tmgvw5 _1tmgvw8 _1tmgvwb _1tmgvwc _1tmgvwf yvsb870 yvsb87f _14uh994h\", href=True) #find all the data from html of respective class\n",
    "            for item in soup: # iterates through the items which has href links\n",
    "                if item['href'].startswith('/job/'):\n",
    "                    job_link.append('https://www.seek.co.nz'+item['href']) # adds the iterted data to the empty list\n",
    "                    Category.append('Data Science')\n",
    "    except:\n",
    "        pass         \n",
    "    return job_link,Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link,Category = seek_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df=pd.DataFrame({\"Category\":Category,\"Job_Posting_link\":job_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df.to_csv('Data_science_seek_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.read_csv(\"Data_science_seek_links.csv\")\n",
    "ml = pd.read_csv('Machine_Learning_seek_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seek_details_extractor(df): # this function extracts the data from the particular job link\n",
    "    seek_df =  pd.DataFrame\n",
    "    for i in range(0,len(df)): #it iterates through the links upto the extracted links length\n",
    "        try:\n",
    "            Job_Posting_link=df['Job_Posting_link'][i] #iterates through the links in the dataframe\n",
    "            Category=df['Category'][i]\n",
    "            w2=requests.get(Job_Posting_link,proxy)\n",
    "            soups1=BeautifulSoup(w2.content,'html.parser') \n",
    "            try:\n",
    "                Location=soups1.find(class_='yvsb870 _14uh994bi').text #extracts the text data from the respective class\n",
    "                pass\n",
    "            except:\n",
    "                Location=None\n",
    "            try:\n",
    "                company = soups1.find(class_ = 'yvsb870 _14uh9944u _1qw3t4i0 _1qw3t4i1x _1qw3t4i2 _1d0g9qk4 _1qw3t4ie').text\n",
    "                pass\n",
    "            except:\n",
    "                company=None\n",
    "            try:\n",
    "                title = soups1.find(class_ = 'yvsb870 _1qw3t4i0 _1qw3t4ih _1d0g9qk4 _1qw3t4im _1qw3t4i1x').text\n",
    "                pass\n",
    "            except:\n",
    "                title=None\n",
    "            try:\n",
    "                desc = soups1.find(class_='yvsb870 _1v38w810').text\n",
    "                pass\n",
    "            except:\n",
    "                desc=None\n",
    "            seek=pd.DataFrame({'Category':Category,'Job_Posting_link':Job_Posting_link,'Job_title':title,'Company_name':company,'Location':Location,'Description':[desc]},index=[0])\n",
    "            # print(simplyhired1)\n",
    "            seek_df=seek_df.append(seek)\n",
    "        except Exception as e: # raises an exception if something goes wrong in the time of extraction\n",
    "            print(e)   \n",
    "    return seek_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science= seek_details_extractor(ds) #calls the above funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning = seek_details_extractor(ml) #calls the above funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science.to_csv(\"seek_Data_science_full_details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_learning.to_csv(\"seek_machine_learning_full_details.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9958a2ee1ad7ce5bed12c6dea2733b89eb37390d2e7528d87543b903c6138a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
