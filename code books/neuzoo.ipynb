{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "proxy = \"http://45.140.13.124:9137\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 100.0.4896\n",
      "Get LATEST chromedriver version for 100.0.4896 google-chrome\n",
      "Driver [C:\\Users\\Pfactorial00110\\.wdm\\drivers\\chromedriver\\win32\\100.0.4896.60\\chromedriver.exe] found in cache\n",
      "C:\\Users\\Pfactorial00110\\AppData\\Local\\Temp\\ipykernel_6816\\3269282774.py:18: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(options=options, executable_path=ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "def getdriver(): #it is the selenium driver to connect the script with the browser\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('log-level=3')\n",
    "    options.add_argument(\"--window-size=1880x1020\")\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"test-type\")\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    options.add_argument('--proxy-server=%s' % proxy)\n",
    "    driver=webdriver.Chrome(options=options, executable_path=ChromeDriverManager().install())\n",
    "    #     driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.53 Safari/537.36'})\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\"source\": \"\"\"\n",
    "    Object.defineProperty(navigator, 'webdriver', {\n",
    "        get: () => undefined\n",
    "    })\n",
    "    \"\"\"})\n",
    "    return driver\n",
    "driver = getdriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link = []\n",
    "Category = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def neuvoo_extractor():#this functions extracts the job links from the particular websie\n",
    "  try:\n",
    "    for i in range(1,3): # iterates upto 10 pages\n",
    "      url_next='https://neuvoo.ca/jobs/?k=data+science&l=&f=&o=&p=&r=15'\n",
    "      w1=requests.get(url_next,proxy) # to access the url\n",
    "      soups=BeautifulSoup(w1.content,'html.parser') \n",
    "      for item in soups.findAll(\"h2\", itemprop='title'): # iterates through the items which has href links\n",
    "        for a in item.findAll('a', href=True):\n",
    "          job_link.append('https://www.neuvoo.com'+a['href']) # adds the iterted data to the empty list\n",
    "          Category.append('Data Science')\n",
    "  except:\n",
    "    pass\n",
    "  return job_link,Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuvoo_extractor():#this functions extracts the job links from the particular websie\n",
    "  try:\n",
    "    for i in range(0,10): # iterates upto 10 pages\n",
    "      url_next='https://neuvoo.ca/jobs/?k=machine+learning&l=&p='+str(i)+'&date=&field=&company=&source_type=&radius=&from=&test=&iam=&is_category=no'\n",
    "      driver.get(url_next) # to access the url\n",
    "      content = driver.page_source \n",
    "      soups=BeautifulSoup(content,'html.parser')\n",
    "      for i in soups.find_all(class_='card card__job'):\n",
    "        ids = i['dataid']\n",
    "        Category.append('Machine Learning')\n",
    "        job_link.append('https://ca.talent.com/view?id='+str(ids)+'&context=geo_bulk_bounce&e=1')\n",
    "  except:\n",
    "    pass\n",
    "  return job_link,Category\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link,Category = neuvoo_extractor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df=pd.DataFrame({\"Category\":Category,\"Job_Posting_link\":job_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df.to_csv('Machine_Learning_neuvoo_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS_links = pd.read_csv(\"Data_science_neuvoo_links.csv\")\n",
    "ML_links = pd.read_csv(\"Machine_Learning_neuvoo_links.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neuvoo_details_extractor(df): # this function extracts the data from the particular job link\n",
    "    neuvoo_df = pd.DataFrame()\n",
    "    for i in range(0,len(df)): #it iterates through the links upto the extracted links length\n",
    "        try:\n",
    "            Job_Posting_link=df['Job_Posting_link'][i] #iterates through the links in the dataframe\n",
    "            Category=df['Category'][i]\n",
    "            driver.get(Job_Posting_link)\n",
    "            content = driver.page_source\n",
    "            soups1=BeautifulSoup(content,'html.parser')\n",
    "            try:\n",
    "                Location=soups1.find(class_='job__header__location').text #extracts the text data from the respective class\n",
    "                pass\n",
    "            except:\n",
    "                Location=None\n",
    "            try:\n",
    "                company = soups1.find(class_ = 'job__header__company').text\n",
    "                pass\n",
    "            except:\n",
    "                company=None\n",
    "            try:\n",
    "                title = soups1.find(class_ = 'job__header__title').text\n",
    "                pass\n",
    "            except:\n",
    "                title=None\n",
    "            try:\n",
    "                salary = soups1.find(class_ ='salary').text\n",
    "                pass\n",
    "            except:\n",
    "                salary=None\n",
    "            try:\n",
    "                description = soups1.find(class_='job__description').text\n",
    "            except:\n",
    "                description=None\n",
    "            neuvoo=pd.DataFrame({'Category':Category,'Job_Posting_link':Job_Posting_link,'Job_title':title,'Company_name':company,'Location':Location,'Description':[description]},index=[0])\n",
    "            # print(simplyhired1)\n",
    "            neuvoo_df=neuvoo_df.append(neuvoo)\n",
    "        except Exception as e: # raises an exception if something goes wrong in the time of extraction\n",
    "            print(e)   \n",
    "    return neuvoo_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data_science = neuvoo_details_extractor(DS_links) #calls the above funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "Machine_Learning = neuvoo_details_extractor(ML_links) #calls the above funtion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_science.to_csv(\"neuvoo_DS_full_details.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_Learning.to_csv(\"neuvoo_ML_full_details.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9958a2ee1ad7ce5bed12c6dea2733b89eb37390d2e7528d87543b903c6138a8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
