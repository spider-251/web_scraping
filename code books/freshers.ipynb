{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.options import Options as FirefoxOptions\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "import re\n",
    "import requests\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current google-chrome version is 101.0.4951\n",
      "Get LATEST chromedriver version for 101.0.4951 google-chrome\n",
      "Driver [C:\\Users\\Pfactorial00110\\.wdm\\drivers\\chromedriver\\win32\\101.0.4951.41\\chromedriver.exe] found in cache\n",
      "C:\\Users\\Pfactorial00110\\AppData\\Local\\Temp\\ipykernel_2712\\4128986626.py:17: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(options=options, executable_path=ChromeDriverManager().install())\n"
     ]
    }
   ],
   "source": [
    "def getdriver(): #it is the selenium driver to connect the script with the browser\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('log-level=3')\n",
    "    options.add_argument(\"--window-size=1880x1020\")\n",
    "    options.add_argument('--disable-extensions')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    #options.add_argument(\"--headless\")\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\" : 2}\n",
    "    options.add_experimental_option(\"prefs\",prefs)\n",
    "    options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    options.add_experimental_option('useAutomationExtension', False)\n",
    "    options.add_argument(\"test-type\")\n",
    "    options.add_argument(\"--disable-web-security\")\n",
    "    options.add_argument(\"--allow-running-insecure-content\")\n",
    "    driver=webdriver.Chrome(options=options, executable_path=ChromeDriverManager().install())\n",
    "    #     driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    driver.execute_cdp_cmd('Network.setUserAgentOverride', {\"userAgent\": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.53 Safari/537.36'})\n",
    "    driver.execute_cdp_cmd(\"Page.addScriptToEvaluateOnNewDocument\", {\"source\": \"\"\"\n",
    "    Object.defineProperty(navigator, 'webdriver', {\n",
    "        get: () => undefined\n",
    "    })\n",
    "    \"\"\"})\n",
    "    return driver\n",
    "driver = getdriver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "job_link = []\n",
    "Category = []\n",
    "def extract_job_post(): # this function extracts the particular data of the mentioned website\n",
    "   try: \n",
    "      for i in range(0,10):\n",
    "         url_next=\"https://jobs.freshershome.com/page\"+str(i)+\"?action=search&5=machine+learning\" #url to extract\n",
    "         driver.get(url_next) #connects to the browser\n",
    "         content = driver.page_source # stores page source in a variable\n",
    "         soups=BeautifulSoup(content, 'html.parser') \n",
    "         soup=soups.findAll('a',href=True) # finds all the a tags in the respective html\n",
    "         for item in soup:\n",
    "            if item['href'].startswith('https://jobs.freshershome.com/detail/'): #to extract the particular data which starts with particular words\n",
    "               job_link.append(item['href']) #to add the extracted data to the empty list\n",
    "               Category.append('Machine Learning')\n",
    "   except:\n",
    "      pass\n",
    "   return job_link,Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_link, Category = extract_job_post()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df=pd.DataFrame({\"Category\":Category,\"Job_Posting_link\":job_link})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df.to_csv('Data_science_freshershome_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "Job_posting_df.to_csv('Machine_learning_freshershome_links.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "DS = pd.read_csv('Data_science_freshershome_links.csv')\n",
    "ML = pd.read_csv('Machine_learning_freshershome_links.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fresh_details_extractor(df): # this function extracts the data from the particular job link\n",
    "    carbs_df = pd.DataFrame()\n",
    "    for i in range(0,len(df)): #it iterates through the links upto the extracted links length\n",
    "        try:\n",
    "          Job_Posting_link=df['Job_Posting_link'][i] #iterates through the links in the dataframe\n",
    "          Category=df['Category'][i]\n",
    "          driver.get(Job_Posting_link)\n",
    "          #content = driver.page_source\n",
    "          #soups1=BeautifulSoup(content,'html.parser')\n",
    "          details_list = [] \n",
    "          details = driver.find_element(by=By.CLASS_NAME, value='detail-list').find_elements(by=By.TAG_NAME, value='span')\n",
    "          for i in details:\n",
    "            details_list.append(i.text)\n",
    "          try:\n",
    "            Location= details_list[1] #driver.find_element(by=By.XPATH, value='/html/body/div/section/div/div[1]/div[1]/div[5]/div[2]/ul/li[2]/span').text #extracts the text data from the respective class                                   #/html/body/div[1]/div[2]/main/div[1]/section[1]/div[3]/div[1]/div[1]/div[1]/p[2]\n",
    "          except:\n",
    "            Location=None                                      #/html/body/div/section/div/div[1]/div[1]/div[7]/div[1]/h4\n",
    "          try:\n",
    "            company = driver.find_element(by=By.XPATH, value=\"/html/body/div/section/div/div[1]/div[1]/div[6]/div[1]/h4\").text #soups1.find(class_ = 'info-org').text\n",
    "          except:\n",
    "            company=None\n",
    "          try:\n",
    "            title = details_list[3] #driver.find_element(by=By.XPATH, value=\"/html/body/div/section/div/div[1]/div[1]/div[5]/div[2]/ul/li[4]/span\").text #soups1.find(class_ = 'info-position').text\n",
    "          except:\n",
    "            title=None\n",
    "          try:\n",
    "              salary = details_list[4] #salary = driver.find_element(by=By.XPATH, value='/html/body/div/section/div/div[1]/div[1]/div[5]/div[2]/ul/li[5]/span').text\n",
    "          except:\n",
    "            salary=None\n",
    "          try:                                                    \n",
    "            description = driver.find_element(by=By.XPATH, value='//*[@id=\"job-details\"]/div[2]').text #soups1.find(class_='job-description').text \n",
    "          except:\n",
    "            description=None\n",
    "          try:\n",
    "            experience = details_list[0] #driver.find_element(by=By.XPATH, value='/html/body/div/section/div/div[1]/div[1]/div[5]/div[2]/ul/li[1]/span').text\n",
    "          except:\n",
    "            experience=None\n",
    "          try:\n",
    "            education = details_list[2] #driver.find_element(by=By.XPATH, value='/html/body/div/section/div/div[1]/div[1]/div[5]/div[2]/ul/li[3]/span').text #('//div[@class=\"col\"][3]').text #/html/body/div[1]/div[2]/main/div[1]/section[1]/div[3]/div[1]/div[1]/div[3]/p[2]\n",
    "          except:\n",
    "            education=None\n",
    "          try:\n",
    "            skills = details_list[6]\n",
    "          except:\n",
    "            skills = None\n",
    "          carbs=pd.DataFrame({'Category':Category,'Job_Posting_link':Job_Posting_link,'Job_title':title,'Company_name':company,'Location':Location,'Education':education,'Salary':salary,'Experience':experience,'Skills':skills,'Description':[description]},index=[0])\n",
    "          carbs_df=carbs_df.append(carbs)\n",
    "        except Exception as e: # raises an exception if something goes wrong in the time of extraction\n",
    "          print(e)\n",
    "    return carbs_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_science = fresh_details_extractor(DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_learning = fresh_details_extractor(ML)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data_science.to_csv('fresherhome_DS_full_details.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "Machine_learning.to_csv('fresherhome_ML_full_details.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ba59a03cf33cb9333b80f44bf9c917041c1cb48ad27ac677fd82dee253b9f056"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
